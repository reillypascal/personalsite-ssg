---
title: AI-Critical Writing and Reporting
description: Reading list of sources critical of AI or reporting on harm caused by its use
fedi_url:
  - https://hachyderm.io/@reillypascal/114597601909960276
  - https://bsky.app/profile/reillypascal.bsky.social/post/3lqflxhpllc2j
date: 2025-05-25T22:40:00-0400
octothorpes:
  - ai
tags:
  - wiki
  - ai
  - politics
  - reading
---

This page is a collection of reporting, research, and essays critical of large language models (LLMs) and other “generative AI.” Articles are organized based on topic. It is an ever-growing list.

## Output Quality

- William Harding, Matthew Kloster, “[Coding on Copilot: 2023 Data Suggests Downward Pressure on Code Quality](https://www.gitclear.com/coding_on_copilot_data_shows_ais_downward_pressure_on_code_quality)”

> We find disconcerting trends for maintainability. Code churn -- the percentage of lines that are reverted or updated less than two weeks after being authored -- is projected to double in 2024 compared to its 2021, pre-AI baseline. We further find that the percentage of “added code” and “copy/pasted code” is increasing in proportion to “updated,” “deleted,” and “moved” code. In this regard, code generated during 2023 more resembles an itinerant contributor, prone to violate the [DRY](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself)-ness of the repos visited.

## AI as a Labor Issue

- Noam Scheiber, “[At Amazon, Some Coders Say Their Jobs Have Begun to Resemble Warehouse Work](https://www.nytimes.com/2025/05/25/business/amazon-ai-coders.html)” ([archived link](https://archive.is/g127S))

> Three Amazon engineers said that managers had increasingly pushed them to use A.I. in their work over the past year. The engineers said that the company had raised output goals and had become less forgiving about deadlines. \[…] One Amazon engineer said his team was roughly half the size it had been last year, but it was expected to produce roughly the same amount of code by using A.I.

### “Human-in-the-loop” as a “reverse centaur”

- Cory Doctorow, “[Pluralistic: “Humans in the loop” must detect the hardest-to-spot errors, at superhuman speed (23 Apr 2024)](https://pluralistic.net/2024/04/23/maximal-plausibility/)”

> Automation can _augment_ a worker. We can call this a “centaur” – the worker offloads a repetitive task, or one that requires a high degree of vigilance, or (worst of all) both. They're a human head on a robot body (hence “centaur”). Think of the sensor/vision system in your car that beeps if you activate your turn-signal while a car is in your blind spot. You're in charge, but you're getting a second opinion from the robot.

- Cory Doctorow, “[Pluralistic: Humans are not perfectly vigilant (01 Apr 2024)](https://pluralistic.net/2024/04/01/human-in-the-loop/)”

> This turns AI-“assisted” coders into _reverse_ centaurs. The AI can churn out code at superhuman speed, and you, the human in the loop, must maintain perfect vigilance and attention as you review that code, spotting the cleverly disguised hooks for malicious code that the AI can't be prevented from inserting into its code.

## Harassment and Spam

- Samantha Cole, “[Schools Are Failing to Protect Students From Non-Consensual Deepfakes, Report Shows](https://www.404media.co/schools-are-failing-to-protect-students-from-non-consensual-deepfakes-report-shows/)”

> “Nudify” and “undress” apps are easy to use and find online and are contributing to the epidemic of explicit deepfakes among teenagers. [Last month Emanuel reported](https://www.404media.co/google-search-includes-paid-promotion-of-nudify-apps/) that Google was promoting these apps in search results: “Google Search didn’t only lead users to these harmful apps, but was also profiting from the apps which pay to place links against specific search terms,” he wrote.

- Emanuel Maiberg, “[No One Knows How to Deal With ‘Student-on-Student’ AI CSAM](https://www.404media.co/no-one-knows-how-to-deal-with-student-on-student-ai-csam/)”

> The report says that while children may recognize that AI-generating nonconsensual content is wrong they can assume “it’s legal, believing that if it were truly illegal, there wouldn’t be an app for it.” The report, which cites several 404 Media stories about this issue, notes that this normalization is in part a result of many “nudify” apps being available on the [Google and Apple app stores](https://www.404media.co/apple-removes-nonconsensual-ai-nude-apps-following-404-media-investigation/), and that their ability to AI-generate nonconsensual nudity is openly advertised to students on [Google](https://www.404media.co/google-search-includes-paid-promotion-of-nudify-apps/) and social media platforms like [Instagram](https://www.404media.co/instagram-ads-send-this-nudify-site-90-percent-of-its-traffic/) and TikTok

- Jason Koebler, “[‘What Was She Supposed to Report?:’ Police Report Shows How a High School Deepfake Nightmare Unfolded](https://www.404media.co/what-was-she-supposed-to-report-police-report-shows-how-a-high-school-deepfake-nightmare-unfolded/)” ([archived link](https://archive.ph/DXLIQ))

- Emanuel Maiberg, “[AI Images in Google Search Results Have Opened a Portal to Hell](https://www.404media.co/google-image-search-ai-results-have-opened-a-portal-to-hell/)” ([archived link](https://archive.ph/ys3ac))

> The news is yet another example of how the tools people have used to navigate the internet for decades are overwhelmed by the flood of AI-generated content even when they are not asking for it and which almost exclusively use people’s work or likeness without consent. At times, the deluge of AI content makes it difficult for users to differentiate between what is real and what is AI-generated.

## AI as an Accountability Sink

- Atay Kozlovski, “[When Algorithms Decide Who is a Target: IDF's use of AI in Gaza](https://www.techpolicy.press/when-algorithms-decide-who-is-a-target-idfs-use-of-ai-in-gaza/)”

> This kind of problem stems from a high level of complexity in the algorithmic structure, which prevents even the designers of the AI system from fully understanding how or why a specific input leads to a specific output. Without such an explanation, it would not only be difficult to dispute the validity of any recommendation provided by the system, but it may also preclude us from holding any involved actor morally responsible as they would not have access to the necessary information required for questioning the output.

## AI and Power

- Ali Alkhatib, “[To Live in Their Utopia: Why Algorithmic Systems Create Absurd Outcomes](https://ali-alkhatib.com/research#utopia)”

> This paper draws from anthropological work on bureaucracies, states, and power, translating these ideas into a theory describing the structural tendency for powerful algorithmic systems to cause tremendous harm. I show how administrative models and projections of the world create marginalization, just as algorithmic models cause representational and allocative harm.

## Economics of AI

- Ed Zitron, “[The Rot-Com Bubble](https://www.wheresyoured.at/rotcombubble/)”

> As we speak, the tech industry is grappling with a mid-life crisis where it desperately searches for the next hyper-growth market, eagerly pushing customers and businesses to adopt technology that nobody asked for in the hopes that they can keep the Rot Economy alive.

- Ed Zitron, “[OpenAI Is a Bad Business](https://www.wheresyoured.at/oai-business/)”

> To be abundantly clear, as it stands, OpenAI currently spends $2.35 to make $1.

## AI and Climate

- Paige Lambermont, “[AI Boom Power Surge: Plants Revived, Fossil Fuels Reconsidered](https://www.independent.org/article/2025/05/08/ai-power-plants-gas-coal/)”

- Dara Kerr, “[AI brings soaring emissions for Google and Microsoft, a major contributor to climate change](https://www.npr.org/2024/07/12/g-s1-9545/ai-brings-soaring-emissions-for-google-and-microsoft-a-major-contributor-to-climate-change)

- [*DOE Releases New Report Evaluating Increase in Electricity Demand from Data Centers*](https://www.energy.gov/articles/doe-releases-new-report-evaluating-increase-electricity-demand-data-centers)

> The report finds that data centers consumed about 4.4% of total U.S. electricity in 2023 and are expected to consume approximately 6.7 to 12% of total U.S. electricity by 2028. The report indicates that total data center electricity usage climbed from 58 TWh in 2014 to 176 TWh in 2023 and estimates an increase between 325 to 580 TWh by 2028.

One might argue that 6.7% of U.S. electricity usage is a relatively small portion of contributions to climate change. However, especially given all the other negatives of LLMs and related technologies, I do not see them as worth that level of energy consumption. See also Molly White, “[AI isn't useless. But is it worth it?](https://www.citationneeded.news/ai-isnt-useless/).”

<!-- - Marc Levy, “[Big Tech’s soaring energy demands are making coal-fired power plant sites attractive](https://apnews.com/article/coal-electricity-artificial-intelligence-trump-power-energy-a3779aee7970dabded42d8d7b3ef3783)” -->

## Discussion Covering Multiple Facets

- Molly White, “[AI isn't useless. But is it worth it?](https://www.citationneeded.news/ai-isnt-useless/)”

- Edward Ongweso Jr., “[The phony comforts of useful idiots](https://thetechbubble.substack.com/p/the-phony-comforts-of-useful-idiots)”